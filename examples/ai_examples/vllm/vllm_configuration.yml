---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: vllm-llama-app
  name: vllm-llama-svc
  namespace: workloads
spec:
  ports:
    - port: 8000
      protocol: TCP
      targetPort: 8000
  selector:
    app: vllm-llama-app
  type: NodePort

---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: vllm-llama-app
  name: vllm-llama
  namespace: workloads
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-llama-app
  template:
    metadata:
      labels:
        app: vllm-llama-app
    spec:
      containers:
        - image: vault.habana.ai/gaudi-docker/1.17.1/ubuntu22.04/habanalabs/pytorch-installer-2.3.1:latest
          name: vllm-llama-openai
          imagePullPolicy: Always
          workingDir: /root
          env:
            - name: HF_HOME
              value: /storage/huggingface
            - name: http_proxy
              value: ""
            - name: https_proxy
              value: ""
            - name: no_proxy
              value: ""
            - name: LLM_MODEL
              value: meta-llama/Meta-Llama-3-70B-Instruct
            - name: HUGGING_FACE_HUB_TOKEN
              value: ""
            - name: HABANA_VISIBLE_DEVICES
              value: all
            - name: NUM_HPU
              value: "4"
            - name: OMPI_MCA_btl_vader_single_copy_mechanism
              value: none
            - name: PT_HPU_ENABLE_LAZY_COLLECTIVES
              value: "true"
          command:
            - "/bin/sh"
            - "-c"
            - |
              git clone -b v0.4.2-Gaudi-1.16.0 https://github.com/HabanaAI/vllm-fork.git
              cd vllm-fork
              pip install -e .
              pip install setuptools==69.0.0
              python -m vllm.entrypoints.openai.api_server --model $LLM_MODEL --dtype auto  --block-size 64 --max-num-seqs 64 --gpu-memory-utilization 0.5 --tensor-parallel-size $NUM_HPU
          ports:
            - containerPort: 8000
              protocol: TCP
          resources:
            limits:
              habana.ai/gaudi: 8
              memory: 400Gi
              hugepages-2Mi: 95000Mi
            requests:
              habana.ai/gaudi: 8
              memory: 400Gi
              hugepages-2Mi: 95000Mi
          volumeMounts:
            - name: datasets
              mountPath: /storage
      volumes:
        - name: datasets
          persistentVolumeClaim:
            claimName: shared-model
            readOnly: false
