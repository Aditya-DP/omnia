---
#- name: Kick CoreDNS (this is a hack that needs to be fixed)
  #shell:  kubectl get pods -n kube-system --no-headers=true | awk '/coredns/{print $1}'|xargs kubectl delete -n kube-system pod
  #tags: init

- name: Wait for CoreDNS to restart 
  shell: kubectl rollout status deployment/coredns -n kube-system
  tags: init

- name: Deploy MetalLB
  shell: kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.8.1/manifests/metallb.yaml
  tags: init

- name: Create MetalLB Setup Config Files
  copy: src=metal-config.yaml dest=/root/k8s/metal-config.yaml owner=root group=root mode=655
  tags: init

- name: Create MetalLB Setup Deployment Files
  copy: src=metallb.yaml dest=/root/k8s/metallb.yaml owner=root group=root mode=655
  tags: init

- name: Deploy MetalLB
  shell: kubectl apply -f /root/k8s/metallb.yaml
  tags: init

- name: Create default setup for MetalLB
  shell: kubectl apply -f /root/k8s/metal-config.yaml
  tags: init

#- name: Helm - create service account
  #shell: kubectl create serviceaccount --namespace kube-system tiller
  #tags: init

#- name: Helm - create clusterRole Binding for tiller-cluster-rule
  #shell: kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
  #tags: init

#- name: Helm - create clusterRoleBinding for admin
  #shell: kubectl create clusterrolebinding tiller-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
  #tags: init

#- name: Helm - init
  #shell: helm init  --upgrade
  #tags: init

#- name: Wait for tiller to start 
  #shell: kubectl rollout status deployment/tiller-deploy -n kube-system
  #tags: init

#- name: Helm - patch cluster Role Binding for tiller
  #shell:  kubectl --namespace kube-system patch deploy tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'
  #tags: init

#- name: Wait for tiller to start 
  #shell: kubectl rollout status deployment/tiller-deploy -n kube-system
  #tags: init

- name: Start K8S Dashboard
  shell: kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta6/aio/deploy/recommended.yaml
  tags: init

- name: Start NFS Client Provisioner
  shell: helm install stable/nfs-client-provisioner --set nfs.server=10.0.0.1 --set nfs.path=/work --generate-name
  tags: init

- name: JupyterHub Persistent Volume Creation (files)  
  copy: src=jhub-db-pv.yaml dest=/root/k8s/jhub-db-pv.yaml owner=root group=root mode=655
  tags: init

- name: jupyterHub Persistent Volume creation
  shell: kubectl create -f /root/k8s/jhub-db-pv.yaml
  tags: init

- name: JupyterHub Custom Config (files)  
  copy: src=jupyter_config.yaml dest=/root/k8s/jupyter_config.yaml owner=root group=root mode=655
  tags: init
 
- name: jupyterHub deploy
  shell: helm install jupyterhub/jupyterhub  --namespace default --version 0.8.2 --values /root/k8s/jupyter_config.yaml --generate-name
  tags: init

- name: Prometheus deployment
  shell: helm install stable/prometheus --set alertmanager.persistentVolume.storageClass=nfs-client,server.persistentVolume.storageClass=nfs-client,server.service.type=LoadBalancer --generate-name
  tags: init

- name: Install MPI Operator
  shell: kubectl create -f https://raw.githubusercontent.com/kubeflow/mpi-operator/master/deploy/mpi-operator.yaml 
  tags: init
